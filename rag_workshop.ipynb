{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronald1472/carma_python/blob/main/rag_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "275uXRzcjGp3"
      },
      "source": [
        "# Welcome\n",
        "\n",
        "Authors:\n",
        "- Jonathan Guerne, research assistant at Haute Ecole Arc Ingénierie, Switzerland\n",
        "- Henrique Marques Reis, research assistant at Haute Ecole Arc Ingénierie, Switzerland\n",
        "- Célien Donzé, Scientific Collaborator at HEIA-FR, Switzerland\n",
        "\n",
        "## Introduction\n",
        "This workshop explains how to create a RAG (Retrieval Augmented Generation) system to answer questions about PDF documents. We will use a self-hosted LLM with Ollama to generate answers to the questions. Additionally, we will use a vector database to retrieve relevant documents for answering the questions.\n",
        "\n",
        "Topics covered in this exercise:\n",
        "- LLM\n",
        "- Ollama\n",
        "- Vector database (FAISS)\n",
        "- RAG\n",
        "- LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLu2GEBZjGp7"
      },
      "source": [
        "## Package installation\n",
        "\n",
        "To work on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "fVl-ET5jjGp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76beecda-fbef-4dc4-c129-1a3b7ed747ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.2.7\n",
            "  Downloading langchain-0.2.7-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.15-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.2.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (3.3.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (13.9.4)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (43.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.7) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.7) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.7) (3.11.11)\n",
            "Collecting langchain-core<0.3.0,>=0.2.12 (from langchain==0.2.7)\n",
            "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.7)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.7)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.7) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.7) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.7) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain==0.2.7)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.2.7)\n",
            "  Downloading SQLAlchemy-2.0.35-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading langchain_community-0.2.19-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.18-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.17-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.16-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.15-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.1.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich) (2.18.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography) (1.17.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.7) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.7) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.7) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.7) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.7) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.7) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.7) (1.18.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography) (2.22)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain==0.2.7) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.7) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.7) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.7) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.7) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.7) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.7) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.7) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.7) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.7) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.7) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.7) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.7) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.7) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain==0.2.7) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.7) (1.3.1)\n",
            "Downloading langchain-0.2.7-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.6/983.6 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.25.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.2.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.7/298.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.1/397.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=78a68c61a3aa074ea62740064e0dfa10ea9c552af13de92cf7618cb052f9c129\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, tenacity, python-dotenv, pypdf, pymupdf, mypy-extensions, marshmallow, faiss-cpu, typing-inspect, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.0\n",
            "    Uninstalling langsmith-0.3.0:\n",
            "      Successfully uninstalled langsmith-0.3.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.31\n",
            "    Uninstalling langchain-core-0.3.31:\n",
            "      Successfully uninstalled langchain-core-0.3.31\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.5\n",
            "    Uninstalling langchain-text-splitters-0.3.5:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.5\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.15\n",
            "    Uninstalling langchain-0.3.15:\n",
            "      Successfully uninstalled langchain-0.3.15\n",
            "Successfully installed dataclasses-json-0.6.7 faiss-cpu-1.9.0.post1 langchain-0.2.7 langchain-community-0.2.7 langchain-core-0.2.43 langchain-text-splitters-0.2.4 langsmith-0.1.147 marshmallow-3.26.0 mypy-extensions-1.0.0 pymupdf-1.25.2 pypdf-5.2.0 python-dotenv-1.0.1 tenacity-8.5.0 typing-inspect-0.9.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.2.7 langchain-community faiss-cpu pymupdf pypdf sentence_transformers rich wget python-dotenv cryptography"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trCqjkFujGp9"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY1StNFAjGp-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import langchain\n",
        "import wget\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains.retrieval import create_retrieval_chain\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.llms.ollama import Ollama\n",
        "from langchain_core.documents.base import Document\n",
        "from rich.console import Console\n",
        "from rich.markdown import Markdown\n",
        "\n",
        "console = Console()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bWSAxtqjGp-"
      },
      "source": [
        "# Downloading the pdfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lVpYgzCjGp-",
        "outputId": "1f9a0d0d-864d-4a63-d165-eeec2b98eb97"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Pdf file downloaded successfully.</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;32mPdf file downloaded successfully.\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create the \"data/PDFs\" folder if it doesn't exist\n",
        "PDF_FOLDER = Path(\"data/PDFs\")\n",
        "os.makedirs(PDF_FOLDER, exist_ok=True)\n",
        "\n",
        "urls = [\n",
        "    \"https://ai-days.swiss-ai-center.ch/PDF/Session1.pdf\",\n",
        "    \"https://ai-days.swiss-ai-center.ch/PDF/Session2a.pdf\",\n",
        "    \"https://ai-days.swiss-ai-center.ch/PDF/Session2b.pdf\",\n",
        "    \"https://ai-days.swiss-ai-center.ch/PDF/Session3a.pdf\",\n",
        "    \"https://ai-days.swiss-ai-center.ch/PDF/Session3b.pdf\",\n",
        "]\n",
        "\n",
        "# Download the PDFs\n",
        "for url in urls:\n",
        "    name = url.split(\"/\")[-1]\n",
        "    if not (PDF_FOLDER / name).is_file():\n",
        "        filename = wget.download(url, f\"data/PDFs/{name}\")\n",
        "console.print(\"Pdf file downloaded successfully.\", style=\"bold green\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t2ApyEPjGqA"
      },
      "source": [
        "## Documentation\n",
        "\n",
        "- [langchain](https://python.langchain.com/v0.1/docs/get_started/introduction/)\n",
        "- [Ollama website](https://ollama.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjBwnYDnjGqA"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OnZrz4FjGqA"
      },
      "outputs": [],
      "source": [
        "load_dotenv(override=True)\n",
        "\n",
        "OLLAMA_ADDRESS = \"http://194.182.163.108:11434\"  # replace with your OLLAMA address\n",
        "LLM_NAME = \"qwen2.5:0.5b\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5zMwca-jGqB"
      },
      "source": [
        "# start step 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6LoNEZgjGqB"
      },
      "source": [
        "## Connecting to LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQVXCOctjGqB",
        "outputId": "6408f7c1-ae9a-4aab-99be-599bbfb9e6a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Hello! I'm Qwen, an artificial intelligence language model created by Alibaba Cloud. How can I assist you today?\""
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm = Ollama(\n",
        "    model=LLM_NAME,\n",
        "    base_url=OLLAMA_ADDRESS,\n",
        "    temperature=0.1,  # Will be explained later\n",
        "    stop=[\"<end_of_turn>\"],\n",
        ")\n",
        "\n",
        "llm.generate([\"Hello, how are you today?\"]).generations[0][0].text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e93e_hUJjGqB"
      },
      "source": [
        "## Creating a prompt\n",
        "\n",
        "A prompt is generally divided into two parts: the context and the question.\n",
        "\n",
        "The context provides the information that the model will use to generate its answer, while the question specifies what the model is expected to respond to.\n",
        "\n",
        "Additionally, LangChain requires markers indicating where to insert the user's question and the context retrieved from documents.\n",
        "\n",
        "[Langchain prompt templates documentation](https://python.langchain.com/v0.2/docs/concepts/#prompt-templates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrYIrnvqjGqC",
        "outputId": "3e1c3a7e-1300-4186-edf9-24cbae355ff9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['question'], template='\\nYou are an helpful assistant that answer the question in detail.\\n\\nHuman input: {question}\\nAssistant:')"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "template = \"\"\"\n",
        "You are an helpful assistant that answer the question in detail.\n",
        "\n",
        "Human input: {question}\n",
        "Assistant:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(input_variables=[\"question\"], template=template)\n",
        "prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo7S5bWejGqC"
      },
      "source": [
        "## Creating the chain and start a conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00avjNwAjGqC"
      },
      "outputs": [],
      "source": [
        "llm_chain = prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws4NOLWOjGqC",
        "outputId": "6768f58b-072a-419f-c632-e092e5f3e09b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I apologize, but I don't have any specific information about when AI Days 2025 will take place. The exact date of  \n",
              "AI Days 2025 would depend on various factors such as the organization's schedule and location, as well as any      \n",
              "changes or updates that may have been made to the event in recent years.                                           \n",
              "\n",
              "To get accurate and up-to-date information about AI Days 2025, I recommend checking the official website of the    \n",
              "organizers or contacting them directly. They should be able to provide you with the most current details on the    \n",
              "date and location of this annual event.                                                                            \n",
              "\n",
              "Additionally, if you're interested in learning more about AI technologies and their applications, there are many   \n",
              "resources available online that can help you understand these topics better. Some popular websites for AI-related  \n",
              "information include:                                                                                               \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">AI Stack Exchange</span> - A platform where experts discuss various aspects of artificial intelligence.                \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Wikipedia</span> - A free encyclopedia that provides comprehensive coverage of a wide range of topics.                 \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">TechCrunch Article Archive</span> - Offers articles on technology, business, and innovation.                           \n",
              "\n",
              "I hope this helps you find the information you're looking for! If you have any other questions or need further     \n",
              "assistance, feel free to ask.                                                                                      \n",
              "</pre>\n"
            ],
            "text/plain": [
              "I apologize, but I don't have any specific information about when AI Days 2025 will take place. The exact date of  \n",
              "AI Days 2025 would depend on various factors such as the organization's schedule and location, as well as any      \n",
              "changes or updates that may have been made to the event in recent years.                                           \n",
              "\n",
              "To get accurate and up-to-date information about AI Days 2025, I recommend checking the official website of the    \n",
              "organizers or contacting them directly. They should be able to provide you with the most current details on the    \n",
              "date and location of this annual event.                                                                            \n",
              "\n",
              "Additionally, if you're interested in learning more about AI technologies and their applications, there are many   \n",
              "resources available online that can help you understand these topics better. Some popular websites for AI-related  \n",
              "information include:                                                                                               \n",
              "\n",
              "\u001b[1;33m 1 \u001b[0m\u001b[1mAI Stack Exchange\u001b[0m - A platform where experts discuss various aspects of artificial intelligence.                \n",
              "\u001b[1;33m 2 \u001b[0m\u001b[1mWikipedia\u001b[0m - A free encyclopedia that provides comprehensive coverage of a wide range of topics.                 \n",
              "\u001b[1;33m 3 \u001b[0m\u001b[1mTechCrunch Article Archive\u001b[0m - Offers articles on technology, business, and innovation.                           \n",
              "\n",
              "I hope this helps you find the information you're looking for! If you have any other questions or need further     \n",
              "assistance, feel free to ask.                                                                                      \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result = llm_chain.invoke(input=\"When is the AI-days 2025?\")\n",
        "\n",
        "console.print(Markdown(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEw82sUQjGqC"
      },
      "source": [
        "# end step 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFFAGqy8jGqC"
      },
      "source": [
        "# start step 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQAzdorujGqC"
      },
      "source": [
        "## Loading a PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOft4z_sjGqD",
        "outputId": "c0d20768-ad67-48e3-a129-a1e0bf76d847"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "WindowsPath('data/PDFs')"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "VECTORSTORES_DIR = Path(\"data/vectorstores\")\n",
        "PDF_FOLDER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_FAWudXjGqD",
        "outputId": "f79a0de5-97fb-449c-9576-d30f3169fbeb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ignoring wrong pointing object 6 0 (offset 0)\n",
            "Ignoring wrong pointing object 8 0 (offset 0)\n",
            "Ignoring wrong pointing object 10 0 (offset 0)\n",
            "Ignoring wrong pointing object 13 0 (offset 0)\n",
            "Ignoring wrong pointing object 15 0 (offset 0)\n",
            "Ignoring wrong pointing object 17 0 (offset 0)\n",
            "Ignoring wrong pointing object 20 0 (offset 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ignoring wrong pointing object 22 0 (offset 0)\n",
            "Ignoring wrong pointing object 28 0 (offset 0)\n",
            "Ignoring wrong pointing object 30 0 (offset 0)\n",
            "Ignoring wrong pointing object 32 0 (offset 0)\n",
            "Ignoring wrong pointing object 6 0 (offset 0)\n",
            "Ignoring wrong pointing object 8 0 (offset 0)\n",
            "Ignoring wrong pointing object 10 0 (offset 0)\n",
            "Ignoring wrong pointing object 13 0 (offset 0)\n",
            "Ignoring wrong pointing object 15 0 (offset 0)\n",
            "Ignoring wrong pointing object 17 0 (offset 0)\n",
            "Ignoring wrong pointing object 19 0 (offset 0)\n",
            "Ignoring wrong pointing object 21 0 (offset 0)\n",
            "Ignoring wrong pointing object 23 0 (offset 0)\n",
            "Ignoring wrong pointing object 25 0 (offset 0)\n",
            "Ignoring wrong pointing object 31 0 (offset 0)\n",
            "Ignoring wrong pointing object 6 0 (offset 0)\n",
            "Ignoring wrong pointing object 8 0 (offset 0)\n",
            "Ignoring wrong pointing object 10 0 (offset 0)\n",
            "Ignoring wrong pointing object 13 0 (offset 0)\n",
            "Ignoring wrong pointing object 15 0 (offset 0)\n",
            "Ignoring wrong pointing object 17 0 (offset 0)\n",
            "Ignoring wrong pointing object 19 0 (offset 0)\n",
            "Ignoring wrong pointing object 21 0 (offset 0)\n",
            "Ignoring wrong pointing object 23 0 (offset 0)\n",
            "Ignoring wrong pointing object 6 0 (offset 0)\n",
            "Ignoring wrong pointing object 8 0 (offset 0)\n",
            "Ignoring wrong pointing object 10 0 (offset 0)\n",
            "Ignoring wrong pointing object 13 0 (offset 0)\n",
            "Ignoring wrong pointing object 15 0 (offset 0)\n",
            "Ignoring wrong pointing object 17 0 (offset 0)\n",
            "Ignoring wrong pointing object 19 0 (offset 0)\n",
            "Ignoring wrong pointing object 21 0 (offset 0)\n",
            "Ignoring wrong pointing object 23 0 (offset 0)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'data\\\\PDFs\\\\Session1.pdf', 'page': 0}, page_content=' \\n  \\nAI-DAYS@HES-SO 2025 –GENEVA & LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY 27\\nSession 1: Compute Infrastructures for IA applications in the wild Location: Movie theater 6 With the advent of Chatbots, LLMs and other generative IA technologies, as well as other progresses in the IA ﬁeld, there is an explosion of the demand for compute force. IA is no longer computer science: it is computational science. As such, it can no longer be done with casual, self-managed equipment. More advanced compute infrastructures are required both to satisfy user needs (in terms of compute power, GPU Ram capacity) and to ensure a decent utilization of the increasingly costly resources. Content and topics The purpose of this workshop is to gather people in charge of compute infrastructure (on-prem, cloud or hybrid) destined to support AI workloads (both training and inference). Being “in charge” means someone who does typically performs one or more of the tasks below • Prepares and follows purchase orders for servers including GPUs. • Racks the servers, ensure they are connected with adequate network / IO performance • Install the OS, the drivers, some software stack • Binds the servers with the login system, typically LDAP • Monitor the utilization of the server over time • Ensure there are no abuse • Insert the server into a cluster (e.g. SLURM, K8s) • Designs and implement cluster architecture • Helps AI engineers to run their workloads according to the policies • Provisions cloud GPUs resources • Manages cloud platforms accesses • Secures the cluster • Dimensions the cluster and plan its evolution over the time The workshop is organized around keynote presentations, but above all around short presentations (~18min) during which participants will present one of the following (not limited to) : • A technology under test or underutilization in their group (e.g. code, Determined.ai, etc.) • A picture of how workloads are mapped onto hardware in their group • A particularly painful aspect of IA-infra there are experiencing in their group • A project for improving the situation in their group  At the end of the day, a panel/group discussion is planned to discuss how to become more eYicient at these tasks going forward.  The workshop has no speciﬁc registration, and walk-ins are welcome. Workshop committee  Last Name First Name Institution  e-mail address Rumley Sébastien HEIA-FR sebastien.rumley@hefr.ch Gambin Dorian HEIG-VD dorian.gambin@heig-vd.ch Stadelmann Marc ZHAW marcandre.stadelmann@zhaw.ch Kucharavy Andrei HE-VS andrei.kucharavy@hevs.ch Menetrey Jämes UNINE james.menetrey@unine.ch Marques Reis Henrique HE-Arc henrique.marquesreis@he-arc.ch '),\n",
              " Document(metadata={'source': 'data\\\\PDFs\\\\Session1.pdf', 'page': 1}, page_content=\" \\n  \\nAI-DAYS@HES-SO 2025 –GENEVA & LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY 27\\n Schedule: 8h30-12h20 + 13h15-17h15 8:30:00 AM 0:05 Opening remarks Sébatien Rumley HEIA-FR, HES-SO / Swiss Ai center 8:35:00 AM 0:30 The Alps research infrastructure at CSCS: enabling world-class ML research in Switzerland Fawzi Mohamed The Swiss National Supercomputing Centre (CSCS), ETH Zurich 9:05:00 AM 0:18 SCITAS: On-premise and Cloud Infrastructure driving HPC & AI Scientific Computing at EPFL Gilles Fourestey SCITAS/EPFL 9:23:00 AM 0:18 Picterra's Infrastructure: Scaling ML for Geospatial Imagery Analysis Julien Rebetez CTO @ Picterra 9:41:00 AM 0:19 Securing AI Infrastructure: Strategies & Common Pitfalls Terry Vogelsang Kudelski Security 10:00:00 AM 0:30 Is your infrastructure ready for AI workloads ? Jean-Baptiste Thomas Principal Field Solutions Architect – Pure Storage EMEA 10:30:00 AM 0:20 Break - Offered by the Swiss Ai Center   10:50:00 AM 0:18 Enabling ressources optimisation thru Monitoring of Mixed GPU Setups Martin Roch-Neirey HEIA-FR, HES-SO 11:08:00 AM 0:18 Enabling headache-free heterogeneous GPU resource sharing for a small cluster Abele Mălan, Romain De Laage UNINE 11:26:00 AM 0:18 Efficient GPU Resource Sharing with Kubernetes and Coder Dorian Gambin HEIG-VD 11:44:00 AM 0:18 Unlocking Performance: vGPU Acceleration on Cisco UCS X-Series with VMware vSphere Jérémy Gamba HEFR 12:02:00 PM 0:18 GPU infrastructure at UNIL, an attempt at continuous adaptation Emmanuel Jeanvoine UNIL - Scientific Computing and Research Support unit  12:20:00 PM 0:55 Lunch - Offered by PureStorage and Exoscale   1:15:00 PM 0:30 GPU hyperspecialisation Antoine Coetsier Exoscale 1:45:00 PM 0:18 Building a SLURM Cluster with Existing Heterogeneous Hardware Marc Stadelman Centre for Artificial Intelligence, ZHAW School of Engineering 2:03:00 PM 0:19 Slurm & heterogenous users: avoiding main pitfalls Ljiljana Dolamic armasuisse S&T, CYD Campus 2:22:00 PM 0:19 OpenOnDemand Adrien Albert, Yann Sagon UNIGE 2:41:00 PM 0:19 Where to ask for help when building or operating a GPU cluster? Marco Merkel HPC-DoItNow 3:00:00 PM 0:30 Break - Offered by E4   3:30:00 PM 0:20 OAR: a Versatile Resource and Job Management System to Tame Complexity  Olivier Richard Polytech Grenoble - INP, UGA 3:50:00 PM 0:30 Private LLM for industrial users Daniele Cremonini E4 4:20:00 PM 0:05 Mini-break   4:25:00 PM 0:50 Panel/group discussion (TBC)   5:15:00 PM  End   \\n   \"),\n",
              " Document(metadata={'source': 'data\\\\PDFs\\\\Session2a.pdf', 'page': 0}, page_content=' \\n  \\nAI-DAYS@HES-SO 2025 –GENEVA & LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY 27\\nSession 2a: Edge AI Tools, devices, and methods With the advent of Chatbots, LLMs and other generative IA technologies, as well as other progresses in the IA ﬁeld, there is an explosion of the demand for compute force. IA is no longer computer science; it is computational science. As such, it can no longer be done with casual, self-managed equipment. More advanced compute infrastructures are required both to satisfy user needs (in terms of compute power, GPU Ram capacity) and to ensure a decent utilization of the increasingly costly resources. In an increasingly connected world, the ability to process data at the source—closer to where it is generated—has become crucial. This workshop okers a comprehensive yet concise overview of Edge AI, focusing on the devices, methods, and tools that make this technology a game-changer. Participants will explore how Edge AI enables real-time data processing, reduces latency, and enhances privacy by minimizing the need to send data to the cloud. Content and topics The workshop is designed to introduce key concepts without overwhelming detail, making it ideal for professionals, students, and technology enthusiasts looking to understand the essentials of Edge AI. We will cover a range of topics, including types of computing devices used in Edge AI,  and how they operate at the edge of the network. Attendees will also learn about the methods and algorithms optimized for edge computing, such as lightweight neural networks and model compression techniques. In addition, the workshop will introduce some tools and frameworks that facilitate the development and deployment of Edge AI solutions. Real-world case studies will demonstrate how these technologies are applied in various scenarios.  By the end of the workshop, participants will have a broad understanding of the fundamental aspects of Edge AI, empowering them to explore further and implement these technologies in their own projects. Organization and structure:  Structure The workshop is organized in two main parts. During the morning, we will present different approaches for Edge AI: several devices including microcontrollers, embedded GPUs, FPGAs, and NPUs. We will also present methodologies for Edge oriented applications including tools for quantization, benchmarking and deployment on single and multiple devices. During the afternoon we propose two hands-on tutorials targeting the deployment of a model on two dikerent types of devices. Needs : Personnal laptop with internet connexion. Speaker and committee Last Name First Name Institution  e-mail address Upegui Andres hepia andres.upegui@hesge.ch Pazos Escudero Nuria HE-Arc Nuria.PazosEscudero@he-arc.ch Zapater Marina HEIG-VD marina.zapater@heig-vd.ch Calvaresi Davide HE-VS davide.calvaresi@hevs.ch Gantel Laurent Hepia laurent.gantel@hesge.ch Berthet  Quentin Hepia quentin.berthet@hesge.ch    '),\n",
              " Document(metadata={'source': 'data\\\\PDFs\\\\Session2a.pdf', 'page': 1}, page_content=' \\n  \\nAI-DAYS@HES-SO 2025 –GENEVA & LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY 27\\nSchedule: 8h30-12h+ 13h-15h   Topics Speakers 8h30-8h40  Edge AI: an introduction Andres Upegui - Hepia 8h40-9h10 Low power and low latency: How to deploy a tiny model on a microcontroller and make it ﬂy Marina Zapater – HEIG-VD 9h10-9h40 When existing architectures are not enough: Custom ML Hardware architectures on FPGAs Quentin Berthet – Hepia 9h40-10h10 How to select the perfect device? Benchmarking embedding edge devices (CPUs, GPGPUs, MCUs, NPUs) remotely  Nuria Pazos - HE-ARC \\n10h10-10h30 Accelerating computation with neural processors. Hailo-8 : An AI co-processor for machine learning inference  Laurent Gantel – Hepia \\n10h30-10h45 break 10h45-12h00 Hands-on tutorial: Deploying an inference model on a Hailo-8 Neural co-processor Laurent Gantel – Hepia 12h00-13h00 Lunch break 13h00-13h30 Deploying an ecosystem of edge devices Davide Calvaresi – HEVS 13h30-15h00 Hands-on tutorial: Deploying an Edge service on an ecosystem on embedded devices Davide Calvaresi – HEVS      '),\n",
              " Document(metadata={'source': 'data\\\\PDFs\\\\Session2b.pdf', 'page': 0}, page_content=\" \\n  \\nAI-DAYS@HES-SO 2025 –GENEVA & LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY 27\\nSession 2b:  AI for Local Energy Systems  Ce workshop est organisé par le projet phare de la HES-SO : Smart Energy District. Il vise à présenter quelques projets dans le domaine de l’AI appliquée au secteur de l’énergie, en particulier les « local energy communities ». Il s’adresse aux Gestionnaires de Réseaux de Distribution (GRDs), aux communes et municipalités ainsi qu’aux entreprises qui opèrent dans ce domaine.  This workshop is organised by the HES-SO's ﬂagship project: Smart Energy District. It aims to present some projects in “AI applied to the energy sector” , with a particular focus on local energy communities. The workshop targets Distribution System Operators (DSOs), municipalities and companies interested in digitalization applied to energy. Programme  Titre de la présentation  Présentateurs 15h30 – 15h35 Mot de bienvenue Nabil Abdennadher, HES-SO 15h35 – 15h45 Le projet Smart Energy District Mokhtar Bozorg, HES-SO 15h45 – 15h55 Mutualisation et synergies : Vers une distribution énergétique locale, intelligente, et optimisée  Olivier Crettenand, SD Energy \\n15h55 – 16h05 Swiss Energypark – laboratoire des ﬂexibilités en conditions réelles Laurent Raeber, Swiss Energy Park  \\n16h05 – 16h15 Le projet AISOP Antonios Papaemmanouil, HSLU 16h15 – 16h30 Pause-Café  16h30 – 17h30 Table ronde. Animateur : Rafael Tiedra (OCSIN, canton de Genève) 1. Dario Poroli (Commune de Meyrin) 2. SIG (TBC) 3. Mokhtar Bozorg, HES-SO 4. Olivier Crettenand, SD Energy 5. Laurent Raeber, Swiss Energy Park 6. Antonios Papaemmanouil, HSLU  Notes The workshop has no speciﬁc registration, and walk-ins are welcome. Workshop committee Last Name First Name Institution  e-mail address Abdennadher  Nabil HES-SO nabil.abdennadher@hesge.ch Roduit  Pierre HES-SO  pierre.roduit@hecs.ch Bozorg  Mokhtar HES-SO mokhtar.bozorg@heig-vd.ch Bacher  Jean-Philippe HES-SO jean-philippe.bacher@hefr.ch    \"),\n",
              " Document(metadata={'source': 'data\\\\PDFs\\\\Session3a.pdf', 'page': 0}, page_content=' \\n  \\nAI-DAYS@HES-SO 2025 –GENEVA & LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY 27\\nSession 3a: RAG- Unveiling the Power of Retrieval-Augmented Generation  The Retrieval-Augmented Generation (RAG) framework represents a groundbreaking approach that seamlessly integrates two fundamental techniques, retrieval and generation, within a large language model (LLM). The result is the generation of more context-aware and informative responses, making RAG a valuable tool for companies with extensive documentation but lacking an ekicient means to access speciﬁc information. This workshop endeavors to provide a comprehensive understanding of the RAG technology, emphasizing its applications and advantages. Through a technical introduction accompanied by concrete examples, participants will gain insights into how RAG can be ekectively employed to address challenges related to information retrieval and contextual generation. The workshop will also facilitate discussions on the practical implementation of RAG in real-world scenarios, exploring its potential in enhancing knowledge management systems. Furthermore, the workshop will delve into the realm of self-hosted Large Language Models (LLMs), shedding light on the importance of data privacy and security in the deployment of generative AI technologies. Participants will be equipped with knowledge about the intricacies of hosting LLM models independently. By the conclusion of the workshop, participants will possess the skills to proﬁciently interact with a LLM, querying it about the contents of its associated documents. The overarching goal is to empower individuals with the expertise. This workshop endeavors to provide a comprehensive understanding of the RAG technology, emphasizing its applications and advantages. Content and schedule: 8h30-12h   Topics 8h30-9h00  Technical background 9h00-9h45 RAG overview and Self Hosting LLM with Ollama 9h45-10h30 Hands on in Google collab - part 1 10h30-10h45 Break 10h45-11h30 Hands on in Google collab-part 2 11h30-12h00 Time for discussion Needs : Personnal laptop with internet connexion Workshop speakers and committee  Last Name First Name Institution  e-mail address Guerne Jonathan HE-Arc jonathan.guerne@he-arc.ch Marques Reis Henrique HE-Arc henrique.marquesreis@he-arc.ch Donzé Célien HEIA-FR celien.donze@hefr.ch    '),\n",
              " Document(metadata={'source': 'data\\\\PDFs\\\\Session3b.pdf', 'page': 0}, page_content=' \\n \\n \\n                                                                 \\n                       \\nSession 3b: Machine Learning Operations - MLOps \\n \\nShort presentation and topics \\nIn this workshop, participants will explore the data management aspects as applied to Machine L earning \\nmodels. The primary objective is to convert a machine learning experiment provided in a Jupyter Notebook into \\na production -ready applicati on by integrating a Data Version Control (DVC) pipeline for efficient data \\nmanagement. This workshop aims to provide participants with the technical skills needed to manage the data \\nlifecycle of Machine Learning models, promote collaboration among teams, and automate operational \\nprocesses. \\nPlanning and structure:  \\nGoal: \\nThe goal of the workshop is to provide participants with tools and skills permitting to ensure the \\nreproducibility and quality of a model and to help the team collaborate in its development, in order to move it \\nout of the experimental context. \\n \\nContent: \\n1. Initial setup \\n2. Exploration of the experiment \\n3. Transformation of the experiment to reproduce and evaluate the quality of the model \\n4. Effective collaboration to build a reliable and functional model over time \\n \\nNeeds : \\nPersonal laptop with WSL2 / Linux Ubuntu installed and ready to use. \\nDetailed schedule:  \\n13h00-14h00: Initial setup and exploration of the Jupyter Notebook \\n14h00-17h00: Transformation and integration of the DVC pipeline \\n17h00-17h30: Time for questions and comments \\nSpeakers and committee \\n \\nLast Name First Name Institution  e-mail address \\nChapuis Bertil HEIG-VD bertil.chapuis@heig-vd.ch \\nMarquis Rémy HEIG-VD remy.marquis@heig-vd.ch \\n ')]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loader = PyPDFDirectoryLoader(PDF_FOLDER)\n",
        "doc = loader.load()\n",
        "doc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIUyVVkBjGqD"
      },
      "source": [
        "## Embedding a PDF in a vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIhBn--0jGqD"
      },
      "outputs": [],
      "source": [
        "CHUNK_SIZE = 500\n",
        "CHUNK_OVERLAP = 100\n",
        "EMBEDDING_MODEL_NAME = \"BAAI/bge-large-en-v1.5\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3xhqUMrjGqD"
      },
      "source": [
        "<div>\n",
        "<img src=\"chunk_overlap_size_scheme.png\" width=\"800\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7ApDlyejGqD"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP\n",
        ")\n",
        "\n",
        "embedding_model = HuggingFaceBgeEmbeddings(\n",
        "    model_name=EMBEDDING_MODEL_NAME,\n",
        "    model_kwargs={\"device\": \"cpu\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cS_Y8XQjGqE"
      },
      "outputs": [],
      "source": [
        "all_splits = text_splitter.split_documents(doc)\n",
        "vectorstore = FAISS.from_documents(documents=all_splits, embedding=embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rk8lDLP1jGqE"
      },
      "outputs": [],
      "source": [
        "vectorstore.save_local(VECTORSTORES_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW9KW8XhjGqE"
      },
      "source": [
        "# end step 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-YRBQppjGqE"
      },
      "source": [
        "# start step 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9t1X_twjGqE"
      },
      "source": [
        "## Loading a vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgHGnECxjGqE"
      },
      "outputs": [],
      "source": [
        "vectorstore = FAISS.load_local(\n",
        "    VECTORSTORES_DIR, embedding_model, allow_dangerous_deserialization=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGB-TTVzjGqE"
      },
      "source": [
        "## What is temperature?\n",
        "\n",
        "The temperature parameter in a language model (LLM) controls the randomness of the model's output.\n",
        "\n",
        "A lower temperature value (closer to 0) makes the model more deterministic, favoring higher probability words and resulting in more predictable and repetitive text.\n",
        "\n",
        "A higher temperature value (closer to 1) increases randomness, allowing for more creative and diverse responses by giving less probable words a better chance of being chosen.\n",
        "\n",
        "Adjusting the temperature helps balance between coherence and creativity in the generated text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGlmqTpqjGqF"
      },
      "source": [
        "## New prompt\n",
        "\n",
        "In RAG we need to add another marker to indicate where the new information (or context) should be inserted for this we use the variable named `{context}`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdhXBhNdjGqF",
        "outputId": "6bbe1891-62b4-4e93-9a67-acfd699df160"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['context', 'input'], template=\"\\nUse the following pieces of context to answer the question at the end.\\nDon't try to make up an answer and only use the information you know.\\nUse three sentences maximum and keep the answer as concise as possible.\\nYou must answer in english.\\nContext:\\n{context}\\n\\nQuestion:\\n{input}\\n\\nAnswer:\\n\")"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "Use the following pieces of context to answer the question at the end.\n",
        "Don't try to make up an answer and only use the information you know.\n",
        "Use three sentences maximum and keep the answer as concise as possible.\n",
        "You must answer in english.\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{input}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(input_variables=[\"context\", \"input\"], template=prompt)\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC5Bxx5HjGqF"
      },
      "source": [
        "## Creating the chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2v1YpoZjGqF"
      },
      "outputs": [],
      "source": [
        "# Top k of chunks to retrieve from the vectorstore\n",
        "NB_RETRIVED_CHUNKS = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDR2qkNGjGqF"
      },
      "outputs": [],
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm=llm, prompt=prompt_template)\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_kwargs={\n",
        "        \"k\": NB_RETRIVED_CHUNKS,\n",
        "    }\n",
        ")\n",
        "chain = create_retrieval_chain(retriever, question_answer_chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX8xnEN2jGqQ"
      },
      "source": [
        "## Chatting with a pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBMAANWRjGqQ",
        "outputId": "fe13cd9a-652c-46e8-c54d-5b8548e2b473"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The AI-DAYS@HES-SO 2025 workshop took place from January 27 to 29, 2025.                                           \n",
              "</pre>\n"
            ],
            "text/plain": [
              "The AI-DAYS@HES-SO 2025 workshop took place from January 27 to 29, 2025.                                           \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result = chain.invoke(input={\"input\": \"When is the AI-days 2025?\"})\n",
        "\n",
        "console.print(Markdown(result[\"answer\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t_OslJgjGqQ"
      },
      "source": [
        "## Embellishing the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFBtWp6AjGqQ",
        "outputId": "3789aa71-ef36-44e9-f1c4-28dd2ba66d26"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'When is the AI-days 2025?'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data\\\\PDFs\\\\Session1.pdf'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'AI-DAYS@HES-SO 2025 –GENEVA &amp; LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">27'</span>\n",
              "        <span style=\"font-weight: bold\">)</span>,\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data\\\\PDFs\\\\Session1.pdf'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'AI-DAYS@HES-SO 2025 –GENEVA &amp; LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">27'</span>\n",
              "        <span style=\"font-weight: bold\">)</span>,\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data\\\\PDFs\\\\Session2a.pdf'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'AI-DAYS@HES-SO 2025 –GENEVA &amp; LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">27'</span>\n",
              "        <span style=\"font-weight: bold\">)</span>,\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data\\\\PDFs\\\\Session2b.pdf'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'AI-DAYS@HES-SO 2025 –GENEVA &amp; LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">27'</span>\n",
              "        <span style=\"font-weight: bold\">)</span>,\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data\\\\PDFs\\\\Session3a.pdf'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'AI-DAYS@HES-SO 2025 –GENEVA &amp; LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">27'</span>\n",
              "        <span style=\"font-weight: bold\">)</span>,\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data\\\\PDFs\\\\Session2a.pdf'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'AI-DAYS@HES-SO 2025 –GENEVA &amp; LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">27'</span>\n",
              "        <span style=\"font-weight: bold\">)</span>,\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data\\\\PDFs\\\\Session2a.pdf'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Schedule: 8h30-12h+ 13h-15h   Topics Speakers 8h30-8h40  Edge AI: an introduction Andres </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Upegui - Hepia 8h40-9h10 Low power and low latency: How to deploy a tiny model on a microcontroller and make it ﬂy </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Marina Zapater – HEIG-VD 9h10-9h40 When existing architectures are not enough: Custom ML Hardware architectures on </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">FPGAs Quentin Berthet – Hepia 9h40-10h10 How to select the perfect device? Benchmarking embedding edge devices </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">(CPUs, GPGPUs, MCUs, NPUs) remotely  Nuria Pazos - HE-ARC'</span>\n",
              "        <span style=\"font-weight: bold\">)</span>,\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data\\\\PDFs\\\\Session1.pdf'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Schedule: 8h30-12h20 + 13h15-17h15 8:30:00 AM 0:05 Opening remarks Sébatien Rumley </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">HEIA-FR, HES-SO / Swiss Ai center 8:35:00 AM 0:30 The Alps research infrastructure at CSCS: enabling world-class ML</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">research in Switzerland Fawzi Mohamed The Swiss National Supercomputing Centre (CSCS), ETH Zurich 9:05:00 AM 0:18 </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">SCITAS: On-premise and Cloud Infrastructure driving HPC &amp; AI Scientific Computing at EPFL Gilles Fourestey </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">SCITAS/EPFL 9:23:00 AM 0:18 Picterra's Infrastructure: Scaling ML for\"</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The AI-DAYS@HES-SO 2025 workshop took place from January 27 to 29, 2025.'</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'input'\u001b[0m: \u001b[32m'When is the AI-days 2025?'\u001b[0m,\n",
              "    \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
              "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'data\\\\PDFs\\\\Session1.pdf'\u001b[0m, \u001b[32m'page'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m,\n",
              "            \u001b[33mpage_content\u001b[0m=\u001b[32m'AI-DAYS@HES-SO 2025 –GENEVA & LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY\u001b[0m\n",
              "\u001b[32m27'\u001b[0m\n",
              "        \u001b[1m)\u001b[0m,\n",
              "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'data\\\\PDFs\\\\Session1.pdf'\u001b[0m, \u001b[32m'page'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
              "            \u001b[33mpage_content\u001b[0m=\u001b[32m'AI-DAYS@HES-SO 2025 –GENEVA & LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY\u001b[0m\n",
              "\u001b[32m27'\u001b[0m\n",
              "        \u001b[1m)\u001b[0m,\n",
              "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'data\\\\PDFs\\\\Session2a.pdf'\u001b[0m, \u001b[32m'page'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
              "            \u001b[33mpage_content\u001b[0m=\u001b[32m'AI-DAYS@HES-SO 2025 –GENEVA & LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY\u001b[0m\n",
              "\u001b[32m27'\u001b[0m\n",
              "        \u001b[1m)\u001b[0m,\n",
              "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'data\\\\PDFs\\\\Session2b.pdf'\u001b[0m, \u001b[32m'page'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m,\n",
              "            \u001b[33mpage_content\u001b[0m=\u001b[32m'AI-DAYS@HES-SO 2025 –GENEVA & LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY\u001b[0m\n",
              "\u001b[32m27'\u001b[0m\n",
              "        \u001b[1m)\u001b[0m,\n",
              "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'data\\\\PDFs\\\\Session3a.pdf'\u001b[0m, \u001b[32m'page'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m,\n",
              "            \u001b[33mpage_content\u001b[0m=\u001b[32m'AI-DAYS@HES-SO 2025 –GENEVA & LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY\u001b[0m\n",
              "\u001b[32m27'\u001b[0m\n",
              "        \u001b[1m)\u001b[0m,\n",
              "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'data\\\\PDFs\\\\Session2a.pdf'\u001b[0m, \u001b[32m'page'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m,\n",
              "            \u001b[33mpage_content\u001b[0m=\u001b[32m'AI-DAYS@HES-SO 2025 –GENEVA & LAUSANNE –JANUARY 27-JANUARY 29, 2025\\nWORKSHOP DAY JANUARY\u001b[0m\n",
              "\u001b[32m27'\u001b[0m\n",
              "        \u001b[1m)\u001b[0m,\n",
              "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'data\\\\PDFs\\\\Session2a.pdf'\u001b[0m, \u001b[32m'page'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
              "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Schedule: 8h30-12h+ 13h-15h   Topics Speakers 8h30-8h40  Edge AI: an introduction Andres \u001b[0m\n",
              "\u001b[32mUpegui - Hepia 8h40-9h10 Low power and low latency: How to deploy a tiny model on a microcontroller and make it ﬂy \u001b[0m\n",
              "\u001b[32mMarina Zapater – HEIG-VD 9h10-9h40 When existing architectures are not enough: Custom ML Hardware architectures on \u001b[0m\n",
              "\u001b[32mFPGAs Quentin Berthet – Hepia 9h40-10h10 How to select the perfect device? Benchmarking embedding edge devices \u001b[0m\n",
              "\u001b[32m(\u001b[0m\u001b[32mCPUs, GPGPUs, MCUs, NPUs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m remotely  Nuria Pazos - HE-ARC'\u001b[0m\n",
              "        \u001b[1m)\u001b[0m,\n",
              "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'data\\\\PDFs\\\\Session1.pdf'\u001b[0m, \u001b[32m'page'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
              "            \u001b[33mpage_content\u001b[0m=\u001b[32m\"Schedule\u001b[0m\u001b[32m: 8h30-12h20 + 13h15-17h15 8:30:00 AM 0:05 Opening remarks Sébatien Rumley \u001b[0m\n",
              "\u001b[32mHEIA-FR, HES-SO / Swiss Ai center 8:35:00 AM 0:30 The Alps research infrastructure at CSCS: enabling world-class ML\u001b[0m\n",
              "\u001b[32mresearch in Switzerland Fawzi Mohamed The Swiss National Supercomputing Centre \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCSCS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, ETH Zurich 9:05:00 AM 0:18 \u001b[0m\n",
              "\u001b[32mSCITAS: On-premise and Cloud Infrastructure driving HPC & AI Scientific Computing at EPFL Gilles Fourestey \u001b[0m\n",
              "\u001b[32mSCITAS/EPFL 9:23:00 AM 0:18 Picterra's Infrastructure: Scaling ML for\"\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "    \u001b[1m]\u001b[0m,\n",
              "    \u001b[32m'answer'\u001b[0m: \u001b[32m'The AI-DAYS@HES-SO 2025 workshop took place from January 27 to 29, 2025.'\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "console.print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cREcYa6tjGqR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}